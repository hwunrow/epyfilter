{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79258,
     "status": "ok",
     "timestamp": 1665648831619,
     "user": {
      "displayName": "Han Yong Wunrow",
      "userId": "03409915919113993012"
     },
     "user_tz": 240
    },
    "id": "Ju-520LgZg22",
    "outputId": "e1749666-a8a0-4349-fe8a-d7a9732ba9ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 589.3 MB 9.3 kB/s \n",
      "\u001b[K     |████████████████████████████████| 6.7 MB 38.0 MB/s \n",
      "\u001b[K     |████████████████████████████████| 439 kB 58.8 MB/s \n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 53.1 MB/s \n",
      "\u001b[K     |████████████████████████████████| 6.0 MB 39.1 MB/s \n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.9.2 requires flatbuffers<2,>=1.12, but you have flatbuffers 22.9.24 which is incompatible.\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip3 install -q tf-nightly tfp-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1665649005385,
     "user": {
      "displayName": "Han Yong Wunrow",
      "userId": "03409915919113993012"
     },
     "user_tz": 240
    },
    "id": "a4V7FKxZZtka"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability.python.internal import samplers\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfes = tfp.experimental.sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Qv_-Ar_aHlb"
   },
   "source": [
    "## Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kVvOab7LaG5B"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-0Ge2wEa4IX"
   },
   "source": [
    "## SIR Dynamics\n",
    "\n",
    "\\begin{array}{l}\n",
    "\\frac{d S}{d t}=-\\frac{\\beta(t) I S}{N} \\\\\n",
    "\\frac{d I}{d t}=\\frac{\\beta(t) I S}{N}-\\gamma I, \\\\\n",
    "\\frac{d R}{d t}=\\gamma I\n",
    "\\end{array}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1665649952499,
     "user": {
      "displayName": "Han Yong Wunrow",
      "userId": "03409915919113993012"
     },
     "user_tz": 240
    },
    "id": "zpN36BnPZ_Sv"
   },
   "outputs": [],
   "source": [
    "SIR = collections.namedtuple(\n",
    "  typename='SIRComponents',\n",
    "  field_names=[\n",
    "    'susceptible',              # S\n",
    "    'infectious',               # I\n",
    "    'recovered',                # R\n",
    "    'daily_new_documented_infectious'])\n",
    "\n",
    "ModelParams = collections.namedtuple(\n",
    "    typename='ModelParams',\n",
    "    field_names=[\n",
    "      'beta',                        # Beta\n",
    "      'average_infection_duration'   # D = 1/gamma\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 228,
     "status": "ok",
     "timestamp": 1665649981305,
     "user": {
      "displayName": "Han Yong Wunrow",
      "userId": "03409915919113993012"
     },
     "user_tz": 240
    },
    "id": "fbkL4HhebWdc"
   },
   "outputs": [],
   "source": [
    "def sample_state_deltas(\n",
    "    state, population, params, seed, is_deterministic=False):\n",
    "  \"\"\"Computes one-step change in state, including Poisson sampling.\n",
    "  \n",
    "  Note that this is coded to support vectorized evaluation on arbitrary-shape\n",
    "  batches of states.  This is useful, for example, for running multiple\n",
    "  independent replicas of this model to compute credible intervals for the\n",
    "  parameters.  We refer to the arbitrary batch shape with the conventional\n",
    "  `B` in the parameter documentation below.  This function also, of course,\n",
    "  supports broadcasting over the batch shape.\n",
    "\n",
    "  Args:\n",
    "    state: A `SIRComponents` tuple with fields Tensors of shape\n",
    "      B + [num_locations] giving the current disease state.\n",
    "    population: A Tensor of shape B + [num_locations] giving the current city\n",
    "      populations.\n",
    "    params: A `ModelParams` tuple with fields Tensors of shape B giving the\n",
    "      global parameters for the current EAKF run.\n",
    "    seed: Initial entropy for pseudo-random number generation.  The Poisson\n",
    "      sampling is repeatable by supplying the same seed.\n",
    "    is_deterministic: A `bool` flag to turn off Poisson sampling if desired.\n",
    "\n",
    "  Returns:\n",
    "    delta: A `SIRComponents` tuple with fields Tensors of shape\n",
    "      B + [num_locations] giving the one-day changes in the state, according\n",
    "      to equations 1-4 above (including Poisson noise per Li et al).\n",
    "  \"\"\"\n",
    "  infectious_fraction = state.infectious / population\n",
    "\n",
    "  # Helper for sampling the Poisson-variate terms.\n",
    "  seeds = samplers.split_seed(seed, n=11)\n",
    "  if is_deterministic:\n",
    "    def sample_poisson(rate):\n",
    "      return rate\n",
    "  else:\n",
    "    def sample_poisson(rate):\n",
    "      return tfd.Poisson(rate=rate).sample(seed=seeds.pop())\n",
    "\n",
    "  dSI = sample_poisson(params.beta * infectious_fraction * state.susceptible)\n",
    "  dIR = sample_poisson(state.infectious / params.average_infection_duration)\n",
    "\n",
    "  # The final state_deltas\n",
    "  return SIRComponents(\n",
    "      susceptible=-dSI,\n",
    "      infectious=dSI - dIR,\n",
    "      recovered=dIR,\n",
    "      daily_new_documented_infectious=dSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1665650034929,
     "user": {
      "displayName": "Han Yong Wunrow",
      "userId": "03409915919113993012"
     },
     "user_tz": 240
    },
    "id": "RnyoAbSdebLv"
   },
   "outputs": [],
   "source": [
    "@tf.function(autograph=False)\n",
    "def rk4_one_step(state, population, mobility_matrix, params, seed):\n",
    "  \"\"\"Implement one step of RK4, wrapped around a call to sample_state_deltas.\"\"\"\n",
    "  # One seed for each RK sub-step\n",
    "  seeds = samplers.split_seed(seed, n=4)\n",
    "\n",
    "  deltas = tf.nest.map_structure(tf.zeros_like, state)\n",
    "  combined_deltas = tf.nest.map_structure(tf.zeros_like, state)\n",
    "\n",
    "  for a, b in zip([1., 2, 2, 1.], [6., 3., 3., 6.]):\n",
    "    next_input = tf.nest.map_structure(\n",
    "        lambda x, delta, a=a: x + delta / a, state, deltas)\n",
    "    deltas = sample_state_deltas(\n",
    "        next_input,\n",
    "        population,\n",
    "        params,\n",
    "        seed=seeds.pop(), is_deterministic=False)\n",
    "    combined_deltas = tf.nest.map_structure(\n",
    "        lambda x, delta, b=b: x + delta / b, combined_deltas, deltas)\n",
    "\n",
    "  return tf.nest.map_structure(\n",
    "      lambda s, delta: s + tf.round(delta),\n",
    "      state, combined_deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1665650216775,
     "user": {
      "displayName": "Han Yong Wunrow",
      "userId": "03409915919113993012"
     },
     "user_tz": 240
    },
    "id": "Hbm5RNY4ef1d"
   },
   "outputs": [],
   "source": [
    "def initialize_state(num_particles, num_batches, seed):\n",
    "  \"\"\"Initialize the state for a batch of EAKF runs.\n",
    "  \n",
    "  Args:\n",
    "    num_particles: `int` giving the number of particles for the EAKF.\n",
    "    num_batches: `int` giving the number of independent EAKF runs to\n",
    "      initialize in a vectorized batch.\n",
    "    seed: PRNG entropy.\n",
    "    \n",
    "  Returns:\n",
    "    state: A `SIRComponents` tuple with Tensors of shape [num_particles,\n",
    "      num_batches, num_cities] giving the initial conditions in each\n",
    "      city, in each filter particle, in each batch member.\n",
    "  \"\"\"\n",
    "  state_shape = [num_particles, num_batches]\n",
    "  susceptible = initial_population * np.ones(state_shape, dtype=np.float32)\n",
    "  infectious = np.zeros(state_shape, dtype=np.float32)\n",
    "  daily_new_documented_infectious = np.zeros(state_shape, dtype=np.float32)\n",
    "\n",
    "  # Following Li et al, initialize Wuhan with up to 2000 people exposed\n",
    "  # and another up to 2000 undocumented infectious.\n",
    "  rng = np.random.RandomState(seed[0] % (2**31 - 1))\n",
    "  wuhan_exposed = rng.randint(\n",
    "      0, 2001, [num_particles, num_batches]).astype(np.float32)\n",
    "  wuhan_undocumented_infectious = rng.randint(\n",
    "      0, 2001, [num_particles, num_batches]).astype(np.float32)\n",
    " \n",
    "  # Also following Li et al, initialize cities adjacent to Wuhan with three\n",
    "  # days' worth of additional exposed and undocumented-infectious cases,\n",
    "  # as they may have traveled there before the beginning of the modeling\n",
    "  # period.\n",
    "  exposed = 3 * mobility_matrix_over_time[\n",
    "      WUHAN_IDX, :, 0] * wuhan_exposed[\n",
    "          ..., np.newaxis] / initial_population[WUHAN_IDX]\n",
    "  undocumented_infectious = 3 * mobility_matrix_over_time[\n",
    "      WUHAN_IDX, :, 0] * wuhan_undocumented_infectious[\n",
    "          ..., np.newaxis] / initial_population[WUHAN_IDX]\n",
    "\n",
    "  exposed[..., WUHAN_IDX] = wuhan_exposed\n",
    "  undocumented_infectious[..., WUHAN_IDX] = wuhan_undocumented_infectious\n",
    "\n",
    "  # Following Li et al, we do not remove the initial exposed and infectious\n",
    "  # persons from the susceptible population.\n",
    "  return SIRComponents(\n",
    "      susceptible=tf.constant(susceptible),\n",
    "      exposed=tf.constant(exposed),\n",
    "      documented_infectious=tf.constant(documented_infectious),\n",
    "      undocumented_infectious=tf.constant(undocumented_infectious),\n",
    "      daily_new_documented_infectious=tf.constant(daily_new_documented_infectious))\n",
    "\n",
    "def update_params(num_particles, num_batches,\n",
    "                  prev_params, parameter_variance, seed):\n",
    "  \"\"\"Update the global parameters between EAKF runs.\n",
    "\n",
    "  Args:\n",
    "    num_particles: `int` giving the number of particles for the EAKF.\n",
    "    num_batches: `int` giving the number of independent EAKF runs to\n",
    "      initialize in a vectorized batch.\n",
    "    prev_params: A `ModelParams` tuple of the parameters used for the previous\n",
    "      EAKF run.\n",
    "    parameter_variance: A `ModelParams` tuple specifying how much to drift\n",
    "      each parameter.\n",
    "    seed: PRNG entropy.\n",
    "    \n",
    "  Returns:\n",
    "    params: A `ModelParams` tuple with fields Tensors of shape\n",
    "      [num_particles, num_batches] giving the global parameters\n",
    "      to use for the next batch of EAKF runs.\n",
    "  \"\"\"\n",
    "  # Initialize near the previous set of parameters. This is the first step\n",
    "  # in Iterated Filtering.\n",
    "  seeds = tf.nest.pack_sequence_as(\n",
    "      prev_params, samplers.split_seed(seed, n=len(prev_params)))\n",
    "  return tf.nest.map_structure(\n",
    "      lambda x, v, seed: x + tf.math.sqrt(v) * tf.random.stateless_normal([\n",
    "          num_particles, num_batches, 1], seed=seed),\n",
    "      prev_params, parameter_variance, seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BdrHNbCJfUod"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMyvQrvIuz/BKglGDziR5dQ",
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
